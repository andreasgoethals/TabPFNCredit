{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baf4dc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      " TESTING: MLP on 0001.heloc (LGD)\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Configuration:\n",
      "  Dataset: 0001.heloc\n",
      "  Method: mlp\n",
      "  HPO: No \n",
      "  CV Splits: 3\n",
      "  Row Limit: 1000000\n",
      "  Seed: 42\n",
      "\n",
      "ðŸ”„ Running mlp...\n",
      "{'batch_size': 1024,\n",
      " 'cat_min_frequency': 0.0,\n",
      " 'cat_nan_policy': 'new',\n",
      " 'cat_policy': 'ordinal',\n",
      " 'config': {'general': {},\n",
      "            'model': {'d_layers': [384, 384], 'dropout': 0.1},\n",
      "            'training': {'lr': 0.0003, 'weight_decay': 1e-05}},\n",
      " 'dataset': '0001.heloc',\n",
      " 'dataset_path': './data',\n",
      " 'evaluate_option': 'best-val',\n",
      " 'gpu': '0',\n",
      " 'max_epoch': 200,\n",
      " 'model_path': 'C:\\\\Users\\\\U0152019\\\\AppData\\\\Local\\\\Temp\\\\talent_ckpt_0001.heloc_mlp_fpzhrwgt',\n",
      " 'model_type': 'mlp',\n",
      " 'n_bins': 2,\n",
      " 'n_trials': 100,\n",
      " 'normalization': 'standard',\n",
      " 'num_nan_policy': 'mean',\n",
      " 'num_policy': 'none',\n",
      " 'retune': False,\n",
      " 'save_path': 'C:\\\\Users\\\\U0152019\\\\AppData\\\\Local\\\\Temp\\\\talent_ckpt_0001.heloc_mlp_fpzhrwgt\\\\0001.heloc-mlp\\\\Epoch200BZ1024-Norm-standard-Nan-mean-new-Cat-ordinal',\n",
      " 'seed': 0,\n",
      " 'seed_num': 15,\n",
      " 'tune': False,\n",
      " 'use_float': False,\n",
      " 'workers': 0}\n",
      "{'batch_size': 1024,\n",
      " 'cat_min_frequency': 0.0,\n",
      " 'cat_nan_policy': 'new',\n",
      " 'cat_policy': 'ordinal',\n",
      " 'config': {'general': {},\n",
      "            'model': {'d_layers': [384, 384], 'dropout': 0.1},\n",
      "            'training': {'lr': 0.0003, 'weight_decay': 1e-05}},\n",
      " 'dataset': '0001.heloc',\n",
      " 'dataset_path': './data',\n",
      " 'evaluate_option': 'best-val',\n",
      " 'gpu': '0',\n",
      " 'max_epoch': 200,\n",
      " 'model_path': 'C:\\\\Users\\\\U0152019\\\\AppData\\\\Local\\\\Temp\\\\talent_ckpt_0001.heloc_mlp_fpzhrwgt',\n",
      " 'model_type': 'mlp',\n",
      " 'n_bins': 2,\n",
      " 'n_trials': 100,\n",
      " 'normalization': 'standard',\n",
      " 'num_nan_policy': 'mean',\n",
      " 'num_policy': 'none',\n",
      " 'retune': False,\n",
      " 'save_path': 'C:\\\\Users\\\\U0152019\\\\AppData\\\\Local\\\\Temp\\\\talent_ckpt_0001.heloc_mlp_fpzhrwgt\\\\0001.heloc-mlp\\\\Epoch200BZ1024-Norm-standard-Nan-mean-new-Cat-ordinal',\n",
      " 'seed': 0,\n",
      " 'seed_num': 15,\n",
      " 'tune': False,\n",
      " 'use_float': False,\n",
      " 'workers': 0}\n",
      "{'batch_size': 1024,\n",
      " 'cat_min_frequency': 0.0,\n",
      " 'cat_nan_policy': 'new',\n",
      " 'cat_policy': 'ordinal',\n",
      " 'config': {'general': {},\n",
      "            'model': {'d_layers': [384, 384], 'dropout': 0.1},\n",
      "            'training': {'lr': 0.0003, 'weight_decay': 1e-05}},\n",
      " 'dataset': '0001.heloc',\n",
      " 'dataset_path': './data',\n",
      " 'evaluate_option': 'best-val',\n",
      " 'gpu': '0',\n",
      " 'max_epoch': 200,\n",
      " 'model_path': 'C:\\\\Users\\\\U0152019\\\\AppData\\\\Local\\\\Temp\\\\talent_ckpt_0001.heloc_mlp_fpzhrwgt',\n",
      " 'model_type': 'mlp',\n",
      " 'n_bins': 2,\n",
      " 'n_trials': 100,\n",
      " 'normalization': 'standard',\n",
      " 'num_nan_policy': 'mean',\n",
      " 'num_policy': 'none',\n",
      " 'retune': False,\n",
      " 'save_path': 'C:\\\\Users\\\\U0152019\\\\AppData\\\\Local\\\\Temp\\\\talent_ckpt_0001.heloc_mlp_fpzhrwgt\\\\0001.heloc-mlp\\\\Epoch200BZ1024-Norm-standard-Nan-mean-new-Cat-ordinal',\n",
      " 'seed': 0,\n",
      " 'seed_num': 15,\n",
      " 'tune': False,\n",
      " 'use_float': False,\n",
      " 'workers': 0}\n",
      "âœ“ Completed in 154.6s\n",
      "\n",
      "================================================================================\n",
      " RESULTS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š Regression Metrics (All Folds):\n",
      "  RÂ²:   -2.5678\n",
      "  RMSE: 0.8153\n",
      "  MAE:  0.6764\n",
      "  MSE:  0.6646\n",
      "\n",
      "  Target Distribution:\n",
      "    Mean: 0.6794\n",
      "    Std:  0.4316\n",
      "    Min:  -0.0341\n",
      "    Max:  2.9898\n",
      "\n",
      "================================================================================\n",
      " PER-FOLD BREAKDOWN\n",
      "================================================================================\n",
      "\n",
      " Fold        RÂ²     RMSE  Samples  Time (s)\n",
      "    1 -2.588962 0.819723    22633 52.256101\n",
      "    2 -2.639450 0.821797    22633 48.943338\n",
      "    3 -2.474991 0.804134    22632 52.791651\n",
      "\n",
      "  Average training time: 51.33s per fold\n",
      "  Total training time: 153.99s\n",
      "\n",
      "================================================================================\n",
      " PREDICTION PREVIEW (First 10 samples)\n",
      "================================================================================\n",
      "\n",
      " Fold     True  Predicted    Error\n",
      "    1 0.000000  -1.355060 1.355060\n",
      "    1 0.000000  -0.817461 0.817461\n",
      "    1 0.000000  -0.813419 0.813419\n",
      "    1 0.328597   0.195104 0.133492\n",
      "    1 0.328597   0.190915 0.137682\n",
      "    1 0.328597   0.172762 0.155835\n",
      "    1 0.328597   0.172762 0.155835\n",
      "    1 0.000000  -0.884956 0.884956\n",
      "    1 0.000000  -0.883590 0.883590\n",
      "    1 0.000000  -0.894024 0.894024\n",
      "\n",
      "================================================================================\n",
      " DATASET INFO\n",
      "================================================================================\n",
      "\n",
      "  Dataset: 0001.heloc\n",
      "  Task: regression\n",
      "  Total samples: 67898\n",
      "  Numerical features: 9\n",
      "  Categorical features: 0\n",
      "  Total features: 9\n",
      "\n",
      "================================================================================\n",
      " SUMMARY\n",
      "================================================================================\n",
      "\n",
      "âœ… mlp achieved RÂ² = -2.5678 on 0001.heloc\n",
      "   Total time: 154.6s\n",
      "   HPO: No\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "=================================================================================\n",
    "INDIVIDUAL METHOD TESTER\n",
    "=================================================================================\n",
    "Quick testing script for individual method-dataset combinations.\n",
    "Provides detailed output for debugging and analysis.\n",
    "=================================================================================\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup\n",
    "PROJECT_ROOT = Path.cwd().parent if 'notebooks' in str(Path.cwd()) else Path.cwd()\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.methods.method_runner import run_talent_method\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, f1_score, confusion_matrix,\n",
    "    mean_squared_error, r2_score, mean_absolute_error\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION FUNCTION\n",
    "# =============================================================================\n",
    "\n",
    "def test_method(\n",
    "    task='pd',\n",
    "    dataset='0001.gmsc',\n",
    "    method='xgboost',\n",
    "    tune=False,\n",
    "    # Data params\n",
    "    test_size=0.2,\n",
    "    val_size=0.2,\n",
    "    cv_splits=3,\n",
    "    seed=42,\n",
    "    row_limit=None,\n",
    "    # Training params\n",
    "    max_epoch=50,\n",
    "    batch_size=256,\n",
    "    n_trials=20,\n",
    "    # Display params\n",
    "    n_preview_rows=10,\n",
    "    verbose=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Test a single method on a dataset with detailed output.\n",
    "    \n",
    "    Args:\n",
    "        task: 'pd' (classification) or 'lgd' (regression)\n",
    "        dataset: Dataset name (e.g., '0001.gmsc', '0001.heloc')\n",
    "        method: TALENT method name (e.g., 'xgboost', 'mlp', 'tabpfn')\n",
    "        tune: Whether to use hyperparameter optimization\n",
    "        test_size: Test set fraction\n",
    "        val_size: Validation set fraction\n",
    "        cv_splits: Number of cross-validation folds\n",
    "        seed: Random seed\n",
    "        row_limit: Optional row limit for quick testing\n",
    "        max_epoch: Max epochs for deep methods\n",
    "        batch_size: Batch size for deep methods\n",
    "        n_trials: HPO trials if tune=True\n",
    "        n_preview_rows: Number of prediction rows to show\n",
    "        verbose: Print detailed progress\n",
    "        \n",
    "    Returns:\n",
    "        results: Dictionary with all fold results\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(f\" TESTING: {method.upper()} on {dataset} ({task.upper()})\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Configuration summary\n",
    "    print(f\"\\nðŸ“‹ Configuration:\")\n",
    "    print(f\"  Dataset: {dataset}\")\n",
    "    print(f\"  Method: {method}\")\n",
    "    print(f\"  HPO: {'Yes' if tune else 'No'} {f'({n_trials} trials)' if tune else ''}\")\n",
    "    print(f\"  CV Splits: {cv_splits}\")\n",
    "    print(f\"  Row Limit: {row_limit if row_limit else 'None (full dataset)'}\")\n",
    "    print(f\"  Seed: {seed}\")\n",
    "    \n",
    "    # Run method\n",
    "    print(f\"\\nðŸ”„ Running {method}...\")\n",
    "    start_time = pd.Timestamp.now()\n",
    "    \n",
    "    try:\n",
    "        results = run_talent_method(\n",
    "            task=task,\n",
    "            dataset=dataset,\n",
    "            test_size=test_size,\n",
    "            val_size=val_size,\n",
    "            cv_splits=cv_splits,\n",
    "            seed=seed,\n",
    "            row_limit=row_limit,\n",
    "            method=method,\n",
    "            max_epoch=max_epoch,\n",
    "            batch_size=batch_size,\n",
    "            tune=tune,\n",
    "            n_trials=n_trials,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        \n",
    "        elapsed = (pd.Timestamp.now() - start_time).total_seconds()\n",
    "        \n",
    "        print(f\"âœ“ Completed in {elapsed:.1f}s\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "    \n",
    "    # =============================================================================\n",
    "    # AGGREGATE RESULTS\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\" RESULTS SUMMARY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Collect all predictions\n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "    all_fold_ids = []\n",
    "    \n",
    "    for fold_id, fold_result in results.items():\n",
    "        y_true = fold_result['y_true']\n",
    "        y_pred = fold_result['y_pred']\n",
    "        \n",
    "        all_y_true.extend(y_true)\n",
    "        all_y_pred.extend(y_pred)\n",
    "        all_fold_ids.extend([fold_id] * len(y_true))\n",
    "    \n",
    "    all_y_true = np.array(all_y_true)\n",
    "    all_y_pred = np.array(all_y_pred)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # COMPUTE METRICS\n",
    "    # =============================================================================\n",
    "    \n",
    "    if task == 'pd':  # Classification\n",
    "        # Handle probability predictions\n",
    "        if len(all_y_pred.shape) > 1 and all_y_pred.shape[1] > 1:\n",
    "            y_pred_proba = all_y_pred[:, 1]\n",
    "            y_pred_class = np.argmax(all_y_pred, axis=1)\n",
    "        else:\n",
    "            y_pred_proba = all_y_pred\n",
    "            y_pred_class = (all_y_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Metrics\n",
    "        auc = roc_auc_score(all_y_true, y_pred_proba)\n",
    "        acc = accuracy_score(all_y_true, y_pred_class)\n",
    "        f1 = f1_score(all_y_true, y_pred_class, average='binary')\n",
    "        cm = confusion_matrix(all_y_true, y_pred_class)\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Classification Metrics (All Folds):\")\n",
    "        print(f\"  AUC:      {auc:.4f}\")\n",
    "        print(f\"  Accuracy: {acc:.4f}\")\n",
    "        print(f\"  F1 Score: {f1:.4f}\")\n",
    "        \n",
    "        print(f\"\\n  Confusion Matrix:\")\n",
    "        print(f\"    [[TN={cm[0,0]:4d}  FP={cm[0,1]:4d}]\")\n",
    "        print(f\"     [FN={cm[1,0]:4d}  TP={cm[1,1]:4d}]]\")\n",
    "        \n",
    "        # Class distribution\n",
    "        n_positive = (all_y_true == 1).sum()\n",
    "        n_negative = (all_y_true == 0).sum()\n",
    "        print(f\"\\n  Class Distribution:\")\n",
    "        print(f\"    Negative (0): {n_negative:5d} ({n_negative/len(all_y_true)*100:.1f}%)\")\n",
    "        print(f\"    Positive (1): {n_positive:5d} ({n_positive/len(all_y_true)*100:.1f}%)\")\n",
    "        \n",
    "    else:  # Regression\n",
    "        mse = mean_squared_error(all_y_true, all_y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(all_y_true, all_y_pred)\n",
    "        r2 = r2_score(all_y_true, all_y_pred)\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Regression Metrics (All Folds):\")\n",
    "        print(f\"  RÂ²:   {r2:.4f}\")\n",
    "        print(f\"  RMSE: {rmse:.4f}\")\n",
    "        print(f\"  MAE:  {mae:.4f}\")\n",
    "        print(f\"  MSE:  {mse:.4f}\")\n",
    "        \n",
    "        # Distribution stats\n",
    "        print(f\"\\n  Target Distribution:\")\n",
    "        print(f\"    Mean: {all_y_true.mean():.4f}\")\n",
    "        print(f\"    Std:  {all_y_true.std():.4f}\")\n",
    "        print(f\"    Min:  {all_y_true.min():.4f}\")\n",
    "        print(f\"    Max:  {all_y_true.max():.4f}\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # PER-FOLD BREAKDOWN\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\" PER-FOLD BREAKDOWN\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    fold_metrics = []\n",
    "    \n",
    "    for fold_id, fold_result in results.items():\n",
    "        y_true = fold_result['y_true']\n",
    "        y_pred = fold_result['y_pred']\n",
    "        train_time = fold_result['train_time']\n",
    "        \n",
    "        if task == 'pd':\n",
    "            if len(y_pred.shape) > 1 and y_pred.shape[1] > 1:\n",
    "                y_pred_proba = y_pred[:, 1]\n",
    "            else:\n",
    "                y_pred_proba = y_pred\n",
    "            \n",
    "            fold_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "            fold_metrics.append({\n",
    "                'Fold': fold_id,\n",
    "                'AUC': fold_auc,\n",
    "                'Samples': len(y_true),\n",
    "                'Time (s)': train_time,\n",
    "            })\n",
    "        else:\n",
    "            fold_r2 = r2_score(y_true, y_pred)\n",
    "            fold_rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "            fold_metrics.append({\n",
    "                'Fold': fold_id,\n",
    "                'RÂ²': fold_r2,\n",
    "                'RMSE': fold_rmse,\n",
    "                'Samples': len(y_true),\n",
    "                'Time (s)': train_time,\n",
    "            })\n",
    "    \n",
    "    fold_df = pd.DataFrame(fold_metrics)\n",
    "    print(f\"\\n{fold_df.to_string(index=False)}\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(f\"\\n  Average training time: {fold_df['Time (s)'].mean():.2f}s per fold\")\n",
    "    print(f\"  Total training time: {fold_df['Time (s)'].sum():.2f}s\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # PREDICTION PREVIEW\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\" PREDICTION PREVIEW (First {n_preview_rows} samples)\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    if task == 'pd':\n",
    "        if len(all_y_pred.shape) > 1 and all_y_pred.shape[1] > 1:\n",
    "            preview_pred = all_y_pred[:n_preview_rows, 1]  # Probability of positive class\n",
    "        else:\n",
    "            preview_pred = all_y_pred[:n_preview_rows]\n",
    "    else:\n",
    "        preview_pred = all_y_pred[:n_preview_rows]\n",
    "    \n",
    "    preview_df = pd.DataFrame({\n",
    "        'Fold': all_fold_ids[:n_preview_rows],\n",
    "        'True': all_y_true[:n_preview_rows],\n",
    "        'Predicted': preview_pred,\n",
    "        'Error': np.abs(all_y_true[:n_preview_rows] - preview_pred),\n",
    "    })\n",
    "    \n",
    "    if task == 'pd':\n",
    "        preview_df['Pred_Class'] = (preview_pred > 0.5).astype(int)\n",
    "        preview_df['Correct'] = (preview_df['True'] == preview_df['Pred_Class']).map({True: 'âœ“', False: 'âœ—'})\n",
    "    \n",
    "    print(f\"\\n{preview_df.to_string(index=False)}\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # DATASET INFO\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\" DATASET INFO\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    first_fold = results[list(results.keys())[0]]\n",
    "    info = first_fold['info']\n",
    "    \n",
    "    print(f\"\\n  Dataset: {dataset}\")\n",
    "    print(f\"  Task: {info.get('task_type', 'N/A')}\")\n",
    "    print(f\"  Total samples: {len(all_y_true)}\")\n",
    "    print(f\"  Numerical features: {info.get('n_num_features', 'N/A')}\")\n",
    "    print(f\"  Categorical features: {info.get('n_cat_features', 'N/A')}\")\n",
    "    print(f\"  Total features: {info.get('n_num_features', 0) + info.get('n_cat_features', 0)}\")\n",
    "    if task == 'pd':\n",
    "        print(f\"  Number of classes: {info.get('n_classes', 'N/A')}\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # FINAL SUMMARY\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\" SUMMARY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    if task == 'pd':\n",
    "        print(f\"\\nâœ… {method} achieved AUC = {auc:.4f} on {dataset}\")\n",
    "    else:\n",
    "        print(f\"\\nâœ… {method} achieved RÂ² = {r2:.4f} on {dataset}\")\n",
    "    \n",
    "    print(f\"   Total time: {elapsed:.1f}s\")\n",
    "    print(f\"   HPO: {'Yes' if tune else 'No'}\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\\n\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# EXAMPLE USAGE\n",
    "# =============================================================================\n",
    "\n",
    "# Example 1: Quick test without HPO\n",
    "if __name__ == \"__main__\":\n",
    "    # Classification test\n",
    "    results_pd = test_method(\n",
    "        task='lgd',\n",
    "        dataset='0001.heloc',\n",
    "        method='mlp',\n",
    "        tune=False,\n",
    "        row_limit=1000000,  # Quick test\n",
    "        cv_splits=3,\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.19)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
