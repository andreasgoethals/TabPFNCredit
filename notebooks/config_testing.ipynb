{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "480fa1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 🧪 TEST CASE: VALID: Base config (PD only) ===\n",
      "❌ Validation FAILED unexpectedly:\n",
      "Configuration validation failed:\n",
      "[DATA] paths.pd_dir does not exist: data/raw/pd\n",
      "[DATA] paths.lgd_dir does not exist: data/raw/lgd\n",
      "\n",
      "=== 🧪 TEST CASE: VALID: row_limit None ===\n",
      "❌ Validation FAILED unexpectedly:\n",
      "Configuration validation failed:\n",
      "[DATA] paths.pd_dir does not exist: data/raw/pd\n",
      "[DATA] paths.lgd_dir does not exist: data/raw/lgd\n",
      "\n",
      "=== 🧪 TEST CASE: VALID: early_stopping + patience ===\n",
      "❌ Validation FAILED unexpectedly:\n",
      "Configuration validation failed:\n",
      "[DATA] paths.pd_dir does not exist: data/raw/pd\n",
      "[DATA] paths.lgd_dir does not exist: data/raw/lgd\n",
      "\n",
      "=== 🧪 TEST CASE: ERROR: test_size + val_size > 0.6 ===\n",
      "✅ Validation FAILED as expected:\n",
      "Configuration validation failed:\n",
      "[DATA] test_size + val_size must be ≤ 0.8\n",
      "[DATA] paths.pd_dir does not exist: data/raw/pd\n",
      "[DATA] paths.lgd_dir does not exist: data/raw/lgd\n",
      "\n",
      "=== 🧪 TEST CASE: ERROR: Missing cv_metric ===\n",
      "✅ Validation FAILED as expected:\n",
      "Configuration validation failed:\n",
      "[DATA] paths.pd_dir does not exist: data/raw/pd\n",
      "[DATA] paths.lgd_dir does not exist: data/raw/lgd\n",
      "[EVAL] cv_metric must be a string\n",
      "\n",
      "=== 🧪 TEST CASE: ERROR: categorical_encoding invalid ===\n",
      "✅ Validation FAILED as expected:\n",
      "Configuration validation failed:\n",
      "[DATA] paths.pd_dir does not exist: data/raw/pd\n",
      "[DATA] paths.lgd_dir does not exist: data/raw/lgd\n",
      "[EXP] categorical_encoding must be one of ['embedding', 'indices', 'none', 'onehot', 'ordinal']\n",
      "\n",
      "=== 🧪 TEST CASE: ERROR: early_stopping_patience not integer ===\n",
      "✅ Validation FAILED as expected:\n",
      "Configuration validation failed:\n",
      "[DATA] paths.pd_dir does not exist: data/raw/pd\n",
      "[DATA] paths.lgd_dir does not exist: data/raw/lgd\n",
      "[EXP] early_stopping_patience must be an integer ≥ 1\n",
      "\n",
      "=== 🧪 TEST CASE: ERROR: PD dataset active but no PD metrics ===\n",
      "✅ Validation FAILED as expected:\n",
      "Configuration validation failed:\n",
      "[DATA] paths.pd_dir does not exist: data/raw/pd\n",
      "[DATA] paths.lgd_dir does not exist: data/raw/lgd\n",
      "[EVAL] PD datasets selected but no PD metrics enabled\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import shutil\n",
    "from pprint import pprint\n",
    "import yaml\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Make sure the project root (the folder that contains \"src/\") is on sys.path\n",
    "project_root = Path.cwd().parent  # since the notebook is inside /notebooks/\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.utils.config_reader import ConfigReader\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Utility helpers\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def write_yaml(path: Path, data: dict):\n",
    "    with open(path, \"w\") as f:\n",
    "        yaml.safe_dump(data, f)\n",
    "\n",
    "\n",
    "def make_base_config(tmpdir: Path):\n",
    "    \"\"\"Generate a fully valid config structure based on your current schema.\"\"\"\n",
    "    (tmpdir / \"data/raw/pd\").mkdir(parents=True, exist_ok=True)\n",
    "    (tmpdir / \"data/raw/lgd\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    data = {\n",
    "        \"split\": {\"test_size\": 0.2, \"val_size\": 0.2, \"cv_splits\": 3, \"seed\": 42, \"row_limit\": 1000},\n",
    "        \"paths\": {\"pd_dir\": \"data/raw/pd\", \"lgd_dir\": \"data/raw/lgd\"},\n",
    "        \"dataset_pd\": {\"0001.gmsc\": True},\n",
    "        \"dataset_lgd\": {\"0001.heloc\": False},\n",
    "    }\n",
    "\n",
    "    experiment = {\n",
    "        \"categorical_encoding\": \"ordinal\",\n",
    "        \"numerical_encoding\": \"quantile\",\n",
    "        \"normalization\": \"standard\",\n",
    "        \"num_nan_policy\": \"mean\",\n",
    "        \"cat_nan_policy\": \"most_frequent\",\n",
    "        \"max_epochs\": 10,\n",
    "        \"batch_size\": 32,\n",
    "        \"tune\": True,\n",
    "        \"n_trials\": 5,\n",
    "        \"early_stopping\": True,\n",
    "        \"early_stopping_patience\": 5,\n",
    "    }\n",
    "\n",
    "    evaluation = {\n",
    "        \"round_digits\": 5,\n",
    "        \"cv_metric\": \"f1\",\n",
    "        \"metrics\": {\n",
    "            \"pd\": {\"accuracy\": True, \"f1\": True, \"aucroc\": True},\n",
    "            \"lgd\": {\"mse\": True, \"mae\": True, \"r2\": False, \"rmse\": False},\n",
    "        },\n",
    "    }\n",
    "\n",
    "    methods = {\n",
    "        \"methods\": {\n",
    "            \"pd\": {\"tabpfn\": True, \"rf\": False},\n",
    "            \"lgd\": {\"lr\": False, \"tabpfn\": False},\n",
    "        }\n",
    "    }\n",
    "\n",
    "    cfg_dir = tmpdir / \"config\"\n",
    "    cfg_dir.mkdir()\n",
    "\n",
    "    write_yaml(cfg_dir / \"CONFIG_DATA.yaml\", data)\n",
    "    write_yaml(cfg_dir / \"CONFIG_EXPERIMENT.yaml\", experiment)\n",
    "    write_yaml(cfg_dir / \"CONFIG_EVALUATION.yaml\", evaluation)\n",
    "    write_yaml(cfg_dir / \"CONFIG_METHOD.yaml\", methods)\n",
    "    return cfg_dir\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Core test runner\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def run_test_case(title, override_fn=None, expect_ok=True):\n",
    "    tmpdir = Path(tempfile.mkdtemp())\n",
    "    cfg_dir = make_base_config(tmpdir)\n",
    "\n",
    "    # Apply optional override\n",
    "    if override_fn:\n",
    "        override_fn(cfg_dir)\n",
    "\n",
    "    print(f\"\\n=== 🧪 TEST CASE: {title} ===\")\n",
    "    try:\n",
    "        cfg = ConfigReader(config_dir=str(cfg_dir)).load().validate().to_dict()\n",
    "        if expect_ok:\n",
    "            print(\"✅ Validation PASSED\")\n",
    "            pprint(cfg)\n",
    "        else:\n",
    "            print(\"❌ Expected failure but passed unexpectedly!\")\n",
    "    except Exception as e:\n",
    "        if expect_ok:\n",
    "            print(\"❌ Validation FAILED unexpectedly:\")\n",
    "            print(e)\n",
    "        else:\n",
    "            print(\"✅ Validation FAILED as expected:\")\n",
    "            print(e)\n",
    "    finally:\n",
    "        shutil.rmtree(tmpdir)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# ✅ VALID CASES\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "run_test_case(\"VALID: Base config (PD only)\")\n",
    "\n",
    "run_test_case(\n",
    "    \"VALID: row_limit None\",\n",
    "    lambda d: (\n",
    "        yaml.safe_dump(\n",
    "            {\n",
    "                **yaml.safe_load(open(d / \"CONFIG_DATA.yaml\")),\n",
    "                \"split\": {\"test_size\": 0.2, \"val_size\": 0.2, \"cv_splits\": 3, \"seed\": 42, \"row_limit\": None},\n",
    "            },\n",
    "            open(d / \"CONFIG_DATA.yaml\", \"w\"),\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "run_test_case(\n",
    "    \"VALID: early_stopping + patience\",\n",
    "    lambda d: (\n",
    "        yaml.safe_dump(\n",
    "            {\n",
    "                **yaml.safe_load(open(d / \"CONFIG_EXPERIMENT.yaml\")),\n",
    "                \"early_stopping\": True,\n",
    "                \"early_stopping_patience\": 3,\n",
    "            },\n",
    "            open(d / \"CONFIG_EXPERIMENT.yaml\", \"w\"),\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# ❌ INVALID CASES\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "run_test_case(\n",
    "    \"ERROR: test_size + val_size > 0.6\",\n",
    "    lambda d: (\n",
    "        yaml.safe_dump(\n",
    "            {\n",
    "                **yaml.safe_load(open(d / \"CONFIG_DATA.yaml\")),\n",
    "                \"split\": {\"test_size\": 0.5, \"val_size\": 0.2, \"cv_splits\": 3, \"seed\": 42, \"row_limit\": 1000},\n",
    "            },\n",
    "            open(d / \"CONFIG_DATA.yaml\", \"w\"),\n",
    "        )\n",
    "    ),\n",
    "    expect_ok=False,\n",
    ")\n",
    "\n",
    "run_test_case(\n",
    "    \"ERROR: Missing cv_metric\",\n",
    "    lambda d: (\n",
    "        yaml.safe_dump(\n",
    "            {k: v for k, v in yaml.safe_load(open(d / \"CONFIG_EVALUATION.yaml\")).items() if k != \"cv_metric\"},\n",
    "            open(d / \"CONFIG_EVALUATION.yaml\", \"w\"),\n",
    "        )\n",
    "    ),\n",
    "    expect_ok=False,\n",
    ")\n",
    "\n",
    "run_test_case(\n",
    "    \"ERROR: categorical_encoding invalid\",\n",
    "    lambda d: (\n",
    "        yaml.safe_dump(\n",
    "            {\n",
    "                **yaml.safe_load(open(d / \"CONFIG_EXPERIMENT.yaml\")),\n",
    "                \"categorical_encoding\": \"invalid_option\",\n",
    "            },\n",
    "            open(d / \"CONFIG_EXPERIMENT.yaml\", \"w\"),\n",
    "        )\n",
    "    ),\n",
    "    expect_ok=False,\n",
    ")\n",
    "\n",
    "run_test_case(\n",
    "    \"ERROR: early_stopping_patience not integer\",\n",
    "    lambda d: (\n",
    "        yaml.safe_dump(\n",
    "            {\n",
    "                **yaml.safe_load(open(d / \"CONFIG_EXPERIMENT.yaml\")),\n",
    "                \"early_stopping_patience\": \"five\",\n",
    "            },\n",
    "            open(d / \"CONFIG_EXPERIMENT.yaml\", \"w\"),\n",
    "        )\n",
    "    ),\n",
    "    expect_ok=False,\n",
    ")\n",
    "\n",
    "run_test_case(\n",
    "    \"ERROR: PD dataset active but no PD metrics\",\n",
    "    lambda d: (\n",
    "        yaml.safe_dump(\n",
    "            {\n",
    "                **yaml.safe_load(open(d / \"CONFIG_EVALUATION.yaml\")),\n",
    "                \"metrics\": {\"pd\": {k: False for k in [\"accuracy\", \"f1\", \"aucroc\"]}, \"lgd\": {\"mse\": True, \"mae\": True}},\n",
    "            },\n",
    "            open(d / \"CONFIG_EVALUATION.yaml\", \"w\"),\n",
    "        )\n",
    "    ),\n",
    "    expect_ok=False,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
