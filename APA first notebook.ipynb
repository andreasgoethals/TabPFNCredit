{
 "cells": [
  {
   "cell_type": "code",
   "id": "598c95d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T08:25:34.448587Z",
     "start_time": "2025-05-27T08:25:34.430990Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "# Setup Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer, load_diabetes, load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    root_mean_squared_error,\n",
    "    r2_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "# Baseline Imports\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "\n",
    "import torch\n",
    "\n",
    "from tabpfn import TabPFNClassifier, TabPFNRegressor\n",
    "from tabpfn_extensions.post_hoc_ensembles.sklearn_interface import AutoTabPFNClassifier, AutoTabPFNRegressor\n",
    "\n",
    "if not torch.mps.is_available():\n",
    "    raise SystemError('GPU device not found. For fast training, please enable GPU. See section above for instructions.')"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "72bb6d64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T08:25:35.862155Z",
     "start_time": "2025-05-27T08:25:35.828010Z"
    }
   },
   "source": "df = pd.read_csv(r'/Users/jannispoltier/Documents/Studium/3. Semester/tabpfn_credit_codebase/data/pd/02 taiwan creditcard/taiwan_creditcard.csv')",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "f93abafd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T08:25:41.256710Z",
     "start_time": "2025-05-27T08:25:41.246816Z"
    }
   },
   "source": [
    "def _preprocess_02_taiwan_creditcard(_data):\n",
    "\n",
    "    # Drop ID and useless columns\n",
    "    _data = _data.drop('ID', axis=1)\n",
    "\n",
    "    # Transform\n",
    "    _data['SEX'] = _data['SEX'].replace({'2': 1, '1': 0})\n",
    "\n",
    "    # Split into covariates, labels\n",
    "    y = _data['default.payment.next.month'].values.astype(int)\n",
    "    x = _data.drop('default.payment.next.month', axis=1).values\n",
    "\n",
    "    cols = list(_data.drop('default.payment.next.month', axis=1).columns)\n",
    "\n",
    "    cols_cat = []\n",
    "    cols_num = cols\n",
    "\n",
    "    cols_cat_idx = [cols.index(col) for col in cols_cat if col in cols]\n",
    "    cols_num_idx = [cols.index(col) for col in cols_num if col in cols]\n",
    "\n",
    "    print(\"02_taiwan_creditcard preprocessed\")\n",
    "    print(\"x shape: \", x.shape)\n",
    "    print(\"y shape: \", y.shape)\n",
    "\n",
    "    return x, y, cols, cols_cat, cols_num, cols_cat_idx, cols_num_idx\n",
    "\n",
    "X, y, cols, cols_cat, cols_num, cols_cat_idx, cols_num_idx = _preprocess_02_taiwan_creditcard(df)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02_taiwan_creditcard preprocessed\n",
      "x shape:  (30000, 23)\n",
      "y shape:  (30000,)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "4414aaf6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T08:25:43.446510Z",
     "start_time": "2025-05-27T08:25:43.441222Z"
    }
   },
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "b249e253",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T08:25:46.725139Z",
     "start_time": "2025-05-27T08:25:46.721408Z"
    }
   },
   "source": [
    "from tabpfn_extensions.rf_pfn import (\n",
    "    RandomForestTabPFNClassifier,\n",
    "    RandomForestTabPFNRegressor,\n",
    ")\n",
    "\n",
    "from tabpfn_extensions import TabPFNClassifier, TabPFNRegressor\n",
    "\n",
    "# ----------------------------\n",
    "# Classification - Strategy 1: Random Forest Preprocessing\n",
    "# ----------------------------\n",
    "\n",
    "clf_base = TabPFNClassifier(\n",
    "    ignore_pretraining_limits=True,\n",
    "    inference_config = {\"SUBSAMPLE_SAMPLES\": 10000} # Needs to be set low so that not OOM on fitting intermediate nodes\n",
    ")\n",
    "\n",
    "tabpfn_tree_clf = RandomForestTabPFNClassifier(\n",
    "    tabpfn=clf_base,\n",
    "    verbose=1,\n",
    "    max_predict_time=60, # Will fit for one minute\n",
    "    fit_nodes=True, # Wheather or not to fit intermediate nodes\n",
    "    adaptive_tree=True, # Whather or not to validate if adding a leaf helps or not\n",
    "  )"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "fcbafe70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T08:25:51.634008Z",
     "start_time": "2025-05-27T08:25:51.630455Z"
    }
   },
   "source": [
    "# ----------------------------\n",
    "# Classification - Strategy 2: Subsampled Ensemble using TabPFNClassifier\n",
    "# ----------------------------\n",
    "print(\"\\n--- Classification: Strategy 1 (Subsampled Ensemble) ---\")\n",
    "tabpfn_subsample_clf = TabPFNClassifier(\n",
    "    ignore_pretraining_limits=True,  # (bool) Allows the use of datasets larger than pretraining limits.\n",
    "    n_estimators=32,                 # (int) Number of estimators for ensembling; improves accuracy with higher values.\n",
    "    inference_config={\n",
    "        \"SUBSAMPLE_SAMPLES\": 10000  # (int) Maximum number of samples per inference step to manage memory usage.\n",
    "    },\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Classification: Strategy 1 (Subsampled Ensemble) ---\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "5ea19edd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T09:43:50.587885Z",
     "start_time": "2025-05-27T08:25:56.577665Z"
    }
   },
   "source": [
    "# Compare different machine learning models by training each one multiple times\n",
    "# on different parts of the data and averaging their performance scores for a\n",
    "# more reliable performance estimate\n",
    "\n",
    "assert len(np.unique(y)) <= 10 # Is classification?\n",
    "\n",
    "# Define models\n",
    "models_class = [\n",
    "    ('TabPFN RF', tabpfn_tree_clf),\n",
    "    ('TabPFN Subsample', tabpfn_subsample_clf),\n",
    "    ('XGBoost', XGBClassifier()),\n",
    "    ('CatBoost', CatBoostClassifier(random_state=42, verbose=0)),\n",
    "    ('RandomForest', RandomForestClassifier(random_state=42)),\n",
    "]\n",
    "\n",
    "# Calculate scores\n",
    "cv = KFold(random_state=42, n_splits=3, shuffle=True)\n",
    "scoring = 'roc_auc_ovr' if len(np.unique(y)) > 2 else 'roc_auc'\n",
    "scores_raw_class = {name: cross_val_score(model, X, y, cv=cv, scoring=scoring, verbose=1)\n",
    "          for name, model in models_class}\n",
    "scores_class = {name: scores_raw_class[name].mean()\n",
    "          for name, model in models_class}"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/tabpfn/classifier.py:421: UserWarning: Number of samples 16000 is greater than the maximum Number of samples 10000 supported by the model. You may see degraded performance.\n",
      "  X, y, feature_names_in, n_features_in = validate_Xy_fit(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 19\u001B[39m\n\u001B[32m     17\u001B[39m cv = KFold(random_state=\u001B[32m42\u001B[39m, n_splits=\u001B[32m3\u001B[39m, shuffle=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m     18\u001B[39m scoring = \u001B[33m'\u001B[39m\u001B[33mroc_auc_ovr\u001B[39m\u001B[33m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(np.unique(y)) > \u001B[32m2\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[33m'\u001B[39m\u001B[33mroc_auc\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m19\u001B[39m scores_raw_class = {name: cross_val_score(model, X, y, cv=cv, scoring=scoring, verbose=\u001B[32m1\u001B[39m)\n\u001B[32m     20\u001B[39m           \u001B[38;5;28;01mfor\u001B[39;00m name, model \u001B[38;5;129;01min\u001B[39;00m models_class}\n\u001B[32m     21\u001B[39m scores_class = {name: scores_raw_class[name].mean()\n\u001B[32m     22\u001B[39m           \u001B[38;5;28;01mfor\u001B[39;00m name, model \u001B[38;5;129;01min\u001B[39;00m models_class}\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001B[39m, in \u001B[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    207\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    208\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m    209\u001B[39m         skip_parameter_validation=(\n\u001B[32m    210\u001B[39m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m    211\u001B[39m         )\n\u001B[32m    212\u001B[39m     ):\n\u001B[32m--> \u001B[39m\u001B[32m213\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m func(*args, **kwargs)\n\u001B[32m    214\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    215\u001B[39m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[32m    216\u001B[39m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[32m    217\u001B[39m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[32m    218\u001B[39m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[32m    219\u001B[39m     msg = re.sub(\n\u001B[32m    220\u001B[39m         \u001B[33mr\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mparameter of \u001B[39m\u001B[33m\\\u001B[39m\u001B[33mw+ must be\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    221\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc.\u001B[34m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m must be\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    222\u001B[39m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[32m    223\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:712\u001B[39m, in \u001B[36mcross_val_score\u001B[39m\u001B[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001B[39m\n\u001B[32m    709\u001B[39m \u001B[38;5;66;03m# To ensure multimetric format is not supported\u001B[39;00m\n\u001B[32m    710\u001B[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001B[32m--> \u001B[39m\u001B[32m712\u001B[39m cv_results = cross_validate(\n\u001B[32m    713\u001B[39m     estimator=estimator,\n\u001B[32m    714\u001B[39m     X=X,\n\u001B[32m    715\u001B[39m     y=y,\n\u001B[32m    716\u001B[39m     groups=groups,\n\u001B[32m    717\u001B[39m     scoring={\u001B[33m\"\u001B[39m\u001B[33mscore\u001B[39m\u001B[33m\"\u001B[39m: scorer},\n\u001B[32m    718\u001B[39m     cv=cv,\n\u001B[32m    719\u001B[39m     n_jobs=n_jobs,\n\u001B[32m    720\u001B[39m     verbose=verbose,\n\u001B[32m    721\u001B[39m     fit_params=fit_params,\n\u001B[32m    722\u001B[39m     params=params,\n\u001B[32m    723\u001B[39m     pre_dispatch=pre_dispatch,\n\u001B[32m    724\u001B[39m     error_score=error_score,\n\u001B[32m    725\u001B[39m )\n\u001B[32m    726\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m cv_results[\u001B[33m\"\u001B[39m\u001B[33mtest_score\u001B[39m\u001B[33m\"\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001B[39m, in \u001B[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    207\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    208\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m    209\u001B[39m         skip_parameter_validation=(\n\u001B[32m    210\u001B[39m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m    211\u001B[39m         )\n\u001B[32m    212\u001B[39m     ):\n\u001B[32m--> \u001B[39m\u001B[32m213\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m func(*args, **kwargs)\n\u001B[32m    214\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    215\u001B[39m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[32m    216\u001B[39m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[32m    217\u001B[39m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[32m    218\u001B[39m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[32m    219\u001B[39m     msg = re.sub(\n\u001B[32m    220\u001B[39m         \u001B[33mr\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mparameter of \u001B[39m\u001B[33m\\\u001B[39m\u001B[33mw+ must be\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    221\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc.\u001B[34m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m must be\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    222\u001B[39m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[32m    223\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:423\u001B[39m, in \u001B[36mcross_validate\u001B[39m\u001B[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001B[39m\n\u001B[32m    420\u001B[39m \u001B[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001B[39;00m\n\u001B[32m    421\u001B[39m \u001B[38;5;66;03m# independent, and that it is pickle-able.\u001B[39;00m\n\u001B[32m    422\u001B[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001B[32m--> \u001B[39m\u001B[32m423\u001B[39m results = parallel(\n\u001B[32m    424\u001B[39m     delayed(_fit_and_score)(\n\u001B[32m    425\u001B[39m         clone(estimator),\n\u001B[32m    426\u001B[39m         X,\n\u001B[32m    427\u001B[39m         y,\n\u001B[32m    428\u001B[39m         scorer=scorers,\n\u001B[32m    429\u001B[39m         train=train,\n\u001B[32m    430\u001B[39m         test=test,\n\u001B[32m    431\u001B[39m         verbose=verbose,\n\u001B[32m    432\u001B[39m         parameters=\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    433\u001B[39m         fit_params=routed_params.estimator.fit,\n\u001B[32m    434\u001B[39m         score_params=routed_params.scorer.score,\n\u001B[32m    435\u001B[39m         return_train_score=return_train_score,\n\u001B[32m    436\u001B[39m         return_times=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m    437\u001B[39m         return_estimator=return_estimator,\n\u001B[32m    438\u001B[39m         error_score=error_score,\n\u001B[32m    439\u001B[39m     )\n\u001B[32m    440\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m train, test \u001B[38;5;129;01min\u001B[39;00m indices\n\u001B[32m    441\u001B[39m )\n\u001B[32m    443\u001B[39m _warn_or_raise_about_fit_failures(results, error_score)\n\u001B[32m    445\u001B[39m \u001B[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001B[39;00m\n\u001B[32m    446\u001B[39m \u001B[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001B[39;00m\n\u001B[32m    447\u001B[39m \u001B[38;5;66;03m# the correct key.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/sklearn/utils/parallel.py:74\u001B[39m, in \u001B[36mParallel.__call__\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m     69\u001B[39m config = get_config()\n\u001B[32m     70\u001B[39m iterable_with_config = (\n\u001B[32m     71\u001B[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[32m     72\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[32m     73\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m74\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m().\u001B[34m__call__\u001B[39m(iterable_with_config)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/joblib/parallel.py:1918\u001B[39m, in \u001B[36mParallel.__call__\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m   1916\u001B[39m     output = \u001B[38;5;28mself\u001B[39m._get_sequential_output(iterable)\n\u001B[32m   1917\u001B[39m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[32m-> \u001B[39m\u001B[32m1918\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.return_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(output)\n\u001B[32m   1920\u001B[39m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[32m   1921\u001B[39m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[32m   1922\u001B[39m \u001B[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[32m   1923\u001B[39m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[32m   1924\u001B[39m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[32m   1925\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._lock:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/joblib/parallel.py:1847\u001B[39m, in \u001B[36mParallel._get_sequential_output\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m   1845\u001B[39m \u001B[38;5;28mself\u001B[39m.n_dispatched_batches += \u001B[32m1\u001B[39m\n\u001B[32m   1846\u001B[39m \u001B[38;5;28mself\u001B[39m.n_dispatched_tasks += \u001B[32m1\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1847\u001B[39m res = func(*args, **kwargs)\n\u001B[32m   1848\u001B[39m \u001B[38;5;28mself\u001B[39m.n_completed_tasks += \u001B[32m1\u001B[39m\n\u001B[32m   1849\u001B[39m \u001B[38;5;28mself\u001B[39m.print_progress()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/sklearn/utils/parallel.py:136\u001B[39m, in \u001B[36m_FuncWrapper.__call__\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    134\u001B[39m     config = {}\n\u001B[32m    135\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(**config):\n\u001B[32m--> \u001B[39m\u001B[32m136\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.function(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:910\u001B[39m, in \u001B[36m_fit_and_score\u001B[39m\u001B[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[39m\n\u001B[32m    907\u001B[39m result[\u001B[33m\"\u001B[39m\u001B[33mfit_error\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    909\u001B[39m fit_time = time.time() - start_time\n\u001B[32m--> \u001B[39m\u001B[32m910\u001B[39m test_scores = _score(\n\u001B[32m    911\u001B[39m     estimator, X_test, y_test, scorer, score_params_test, error_score\n\u001B[32m    912\u001B[39m )\n\u001B[32m    913\u001B[39m score_time = time.time() - start_time - fit_time\n\u001B[32m    914\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m return_train_score:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:971\u001B[39m, in \u001B[36m_score\u001B[39m\u001B[34m(estimator, X_test, y_test, scorer, score_params, error_score)\u001B[39m\n\u001B[32m    969\u001B[39m         scores = scorer(estimator, X_test, **score_params)\n\u001B[32m    970\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m971\u001B[39m         scores = scorer(estimator, X_test, y_test, **score_params)\n\u001B[32m    972\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[32m    973\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(scorer, _MultimetricScorer):\n\u001B[32m    974\u001B[39m         \u001B[38;5;66;03m# If `_MultimetricScorer` raises exception, the `error_score`\u001B[39;00m\n\u001B[32m    975\u001B[39m         \u001B[38;5;66;03m# parameter is equal to \"raise\".\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:139\u001B[39m, in \u001B[36m_MultimetricScorer.__call__\u001B[39m\u001B[34m(self, estimator, *args, **kwargs)\u001B[39m\n\u001B[32m    137\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    138\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(scorer, _BaseScorer):\n\u001B[32m--> \u001B[39m\u001B[32m139\u001B[39m         score = scorer._score(\n\u001B[32m    140\u001B[39m             cached_call, estimator, *args, **routed_params.get(name).score\n\u001B[32m    141\u001B[39m         )\n\u001B[32m    142\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    143\u001B[39m         score = scorer(estimator, *args, **routed_params.get(name).score)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:371\u001B[39m, in \u001B[36m_Scorer._score\u001B[39m\u001B[34m(self, method_caller, estimator, X, y_true, **kwargs)\u001B[39m\n\u001B[32m    369\u001B[39m pos_label = \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m is_regressor(estimator) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m._get_pos_label()\n\u001B[32m    370\u001B[39m response_method = _check_response_method(estimator, \u001B[38;5;28mself\u001B[39m._response_method)\n\u001B[32m--> \u001B[39m\u001B[32m371\u001B[39m y_pred = method_caller(\n\u001B[32m    372\u001B[39m     estimator, response_method.\u001B[34m__name__\u001B[39m, X, pos_label=pos_label\n\u001B[32m    373\u001B[39m )\n\u001B[32m    375\u001B[39m scoring_kwargs = {**\u001B[38;5;28mself\u001B[39m._kwargs, **kwargs}\n\u001B[32m    376\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._sign * \u001B[38;5;28mself\u001B[39m._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/sklearn/metrics/_scorer.py:89\u001B[39m, in \u001B[36m_cached_call\u001B[39m\u001B[34m(cache, estimator, response_method, *args, **kwargs)\u001B[39m\n\u001B[32m     86\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m cache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m response_method \u001B[38;5;129;01min\u001B[39;00m cache:\n\u001B[32m     87\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m cache[response_method]\n\u001B[32m---> \u001B[39m\u001B[32m89\u001B[39m result, _ = _get_response_values(\n\u001B[32m     90\u001B[39m     estimator, *args, response_method=response_method, **kwargs\n\u001B[32m     91\u001B[39m )\n\u001B[32m     93\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m cache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m     94\u001B[39m     cache[response_method] = result\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/sklearn/utils/_response.py:211\u001B[39m, in \u001B[36m_get_response_values\u001B[39m\u001B[34m(estimator, X, response_method, pos_label, return_response_method_used)\u001B[39m\n\u001B[32m    208\u001B[39m     \u001B[38;5;28;01melif\u001B[39;00m pos_label \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m target_type == \u001B[33m\"\u001B[39m\u001B[33mbinary\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    209\u001B[39m         pos_label = classes[-\u001B[32m1\u001B[39m]\n\u001B[32m--> \u001B[39m\u001B[32m211\u001B[39m y_pred = prediction_method(X)\n\u001B[32m    213\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m prediction_method.\u001B[34m__name__\u001B[39m \u001B[38;5;129;01min\u001B[39;00m (\u001B[33m\"\u001B[39m\u001B[33mpredict_proba\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mpredict_log_proba\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m    214\u001B[39m     y_pred = _process_predict_proba(\n\u001B[32m    215\u001B[39m         y_pred=y_pred,\n\u001B[32m    216\u001B[39m         target_type=target_type,\n\u001B[32m    217\u001B[39m         classes=classes,\n\u001B[32m    218\u001B[39m         pos_label=pos_label,\n\u001B[32m    219\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/tabpfn_extensions/rf_pfn/sklearn_based_random_forest_tabpfn.py:470\u001B[39m, in \u001B[36mRandomForestTabPFNClassifier.predict_proba\u001B[39m\u001B[34m(self, X)\u001B[39m\n\u001B[32m    466\u001B[39m evaluated_estimators = \u001B[32m0\u001B[39m\n\u001B[32m    468\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m estimator \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.estimators_:\n\u001B[32m    469\u001B[39m     \u001B[38;5;66;03m# Get predictions from this tree\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m470\u001B[39m     proba = estimator.predict_proba(X)\n\u001B[32m    472\u001B[39m     \u001B[38;5;66;03m# If this estimator has fewer classes than the overall set, expand it\u001B[39;00m\n\u001B[32m    473\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m proba.shape[\u001B[32m1\u001B[39m] < \u001B[38;5;28mself\u001B[39m.n_classes_:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/tabpfn_extensions/rf_pfn/sklearn_based_decision_tree_tabpfn.py:1230\u001B[39m, in \u001B[36mDecisionTreeTabPFNClassifier.predict_proba\u001B[39m\u001B[34m(self, X, check_input)\u001B[39m\n\u001B[32m   1224\u001B[39m X = validate_data(\n\u001B[32m   1225\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   1226\u001B[39m     X,\n\u001B[32m   1227\u001B[39m     ensure_all_finite=\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m   1228\u001B[39m )\n\u001B[32m   1229\u001B[39m check_is_fitted(\u001B[38;5;28mself\u001B[39m, [\u001B[33m\"\u001B[39m\u001B[33m_tree\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mX\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33my\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m-> \u001B[39m\u001B[32m1230\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._predict_internal(X, check_input=check_input)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/tabpfn_extensions/rf_pfn/sklearn_based_decision_tree_tabpfn.py:635\u001B[39m, in \u001B[36mDecisionTreeTabPFNBase._predict_internal\u001B[39m\u001B[34m(self, X, y, check_input)\u001B[39m\n\u001B[32m    627\u001B[39m     \u001B[38;5;28mself\u001B[39m.fit_leaves(\u001B[38;5;28mself\u001B[39m.train_X, \u001B[38;5;28mself\u001B[39m.train_y)\n\u001B[32m    628\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    629\u001B[39m         \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mvalid_X\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    630\u001B[39m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m.valid_X \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    633\u001B[39m         \u001B[38;5;66;03m# Force a pass to evaluate node performance\u001B[39;00m\n\u001B[32m    634\u001B[39m         \u001B[38;5;66;03m# so we can prune or decide node updates\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m635\u001B[39m         \u001B[38;5;28mself\u001B[39m._predict_internal(\n\u001B[32m    636\u001B[39m             \u001B[38;5;28mself\u001B[39m.valid_X,\n\u001B[32m    637\u001B[39m             \u001B[38;5;28mself\u001B[39m.valid_y,\n\u001B[32m    638\u001B[39m             check_input=\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m    639\u001B[39m         )\n\u001B[32m    640\u001B[39m \u001B[38;5;66;03m# Now fit leaves again using the entire dataset (train + valid, effectively)\u001B[39;00m\n\u001B[32m    641\u001B[39m \u001B[38;5;28mself\u001B[39m.fit_leaves(\u001B[38;5;28mself\u001B[39m.X, \u001B[38;5;28mself\u001B[39m.y)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/tabpfn_extensions/rf_pfn/sklearn_based_decision_tree_tabpfn.py:758\u001B[39m, in \u001B[36mDecisionTreeTabPFNBase._predict_internal\u001B[39m\u001B[34m(self, X, y, check_input)\u001B[39m\n\u001B[32m    755\u001B[39m         \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[32m    757\u001B[39m \u001B[38;5;66;03m# Perform leaf-level TabPFN prediction\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m758\u001B[39m leaf_prediction = \u001B[38;5;28mself\u001B[39m._predict_leaf(\n\u001B[32m    759\u001B[39m     X_train_leaf,\n\u001B[32m    760\u001B[39m     y_train_leaf,\n\u001B[32m    761\u001B[39m     leaf_id,\n\u001B[32m    762\u001B[39m     X,\n\u001B[32m    763\u001B[39m     test_sample_indices,\n\u001B[32m    764\u001B[39m )\n\u001B[32m    766\u001B[39m \u001B[38;5;66;03m# Evaluate “averaging” and “replacement” for pruning\u001B[39;00m\n\u001B[32m    767\u001B[39m y_prob_averaging, y_prob_replacement = (\n\u001B[32m    768\u001B[39m     \u001B[38;5;28mself\u001B[39m._pruning_get_prediction_type_results(\n\u001B[32m    769\u001B[39m         y_prob,\n\u001B[32m   (...)\u001B[39m\u001B[32m    774\u001B[39m     )\n\u001B[32m    775\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/tabpfn_extensions/rf_pfn/sklearn_based_decision_tree_tabpfn.py:1172\u001B[39m, in \u001B[36mDecisionTreeTabPFNClassifier._predict_leaf\u001B[39m\u001B[34m(self, X_train_leaf, y_train_leaf, leaf_id, X_full, indices)\u001B[39m\n\u001B[32m   1168\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1169\u001B[39m     \u001B[38;5;66;03m# Use direct indexing for numpy\u001B[39;00m\n\u001B[32m   1170\u001B[39m     X_subset = X_full[indices]\n\u001B[32m-> \u001B[39m\u001B[32m1172\u001B[39m proba = \u001B[38;5;28mself\u001B[39m.tabpfn.predict_proba(X_subset)\n\u001B[32m   1173\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i, c \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(classes_in_leaf):\n\u001B[32m   1174\u001B[39m     y_eval_prob[indices, c] = proba[:, i]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/contextlib.py:81\u001B[39m, in \u001B[36mContextDecorator.__call__.<locals>.inner\u001B[39m\u001B[34m(*args, **kwds)\u001B[39m\n\u001B[32m     78\u001B[39m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[32m     79\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minner\u001B[39m(*args, **kwds):\n\u001B[32m     80\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._recreate_cm():\n\u001B[32m---> \u001B[39m\u001B[32m81\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m func(*args, **kwds)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/tabpfn/classifier.py:554\u001B[39m, in \u001B[36mTabPFNClassifier.predict_proba\u001B[39m\u001B[34m(self, X)\u001B[39m\n\u001B[32m    550\u001B[39m X = _process_text_na_dataframe(X, ord_encoder=\u001B[38;5;28mself\u001B[39m.preprocessor_)\n\u001B[32m    552\u001B[39m outputs: \u001B[38;5;28mlist\u001B[39m[torch.Tensor] = []\n\u001B[32m--> \u001B[39m\u001B[32m554\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m output, config \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.executor_.iter_outputs(\n\u001B[32m    555\u001B[39m     X,\n\u001B[32m    556\u001B[39m     device=\u001B[38;5;28mself\u001B[39m.device_,\n\u001B[32m    557\u001B[39m     autocast=\u001B[38;5;28mself\u001B[39m.use_autocast_,\n\u001B[32m    558\u001B[39m ):\n\u001B[32m    559\u001B[39m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(config, ClassifierEnsembleConfig)\n\u001B[32m    560\u001B[39m     \u001B[38;5;66;03m# Cut out logits for classes which do not exist\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/tabpfn/inference.py:332\u001B[39m, in \u001B[36mInferenceEngineCachePreprocessing.iter_outputs\u001B[39m\u001B[34m(self, X, device, autocast, only_return_standard_out)\u001B[39m\n\u001B[32m    326\u001B[39m style = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    328\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m (\n\u001B[32m    329\u001B[39m     torch.autocast(device.type, enabled=autocast),\n\u001B[32m    330\u001B[39m     torch.inference_mode(),\n\u001B[32m    331\u001B[39m ):\n\u001B[32m--> \u001B[39m\u001B[32m332\u001B[39m     output = \u001B[38;5;28mself\u001B[39m.model(\n\u001B[32m    333\u001B[39m         *(style, X_full, y_train),\n\u001B[32m    334\u001B[39m         only_return_standard_out=only_return_standard_out,\n\u001B[32m    335\u001B[39m         categorical_inds=cat_ix,\n\u001B[32m    336\u001B[39m         single_eval_pos=\u001B[38;5;28mlen\u001B[39m(y_train),\n\u001B[32m    337\u001B[39m     )\n\u001B[32m    339\u001B[39m output = output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(output, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m output.squeeze(\u001B[32m1\u001B[39m)\n\u001B[32m    341\u001B[39m \u001B[38;5;28;01myield\u001B[39;00m output, config\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1734\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1735\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1736\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_impl(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1742\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1743\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1744\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1745\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1746\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1747\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(*args, **kwargs)\n\u001B[32m   1749\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1750\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/tabpfn/model/transformer.py:416\u001B[39m, in \u001B[36mPerFeatureTransformer.forward\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    414\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) == \u001B[32m3\u001B[39m:\n\u001B[32m    415\u001B[39m     style, x, y = args\n\u001B[32m--> \u001B[39m\u001B[32m416\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward(x, y, style=style, **kwargs)\n\u001B[32m    418\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mUnrecognized input. Please follow the doc string.\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/tabpfn/model/transformer.py:628\u001B[39m, in \u001B[36mPerFeatureTransformer._forward\u001B[39m\u001B[34m(***failed resolving arguments***)\u001B[39m\n\u001B[32m    620\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    621\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mThere should be no NaNs in the encoded x and y.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    622\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mCheck that you do not feed NaNs or use a NaN-handling enocder.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    623\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mYour embedded x and y returned the following:\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    624\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtorch.isnan(embedded_x).any()\u001B[38;5;132;01m=}\u001B[39;00m\u001B[33m | \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtorch.isnan(embedded_y).any()\u001B[38;5;132;01m=}\u001B[39;00m\u001B[33m\"\u001B[39m,\n\u001B[32m    625\u001B[39m     )\n\u001B[32m    626\u001B[39m \u001B[38;5;28;01mdel\u001B[39;00m embedded_y, embedded_x\n\u001B[32m--> \u001B[39m\u001B[32m628\u001B[39m encoder_out = \u001B[38;5;28mself\u001B[39m.transformer_encoder(\n\u001B[32m    629\u001B[39m     (\n\u001B[32m    630\u001B[39m         embedded_input\n\u001B[32m    631\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m.transformer_decoder\n\u001B[32m    632\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m embedded_input[:, :single_eval_pos_]\n\u001B[32m    633\u001B[39m     ),\n\u001B[32m    634\u001B[39m     single_eval_pos=single_eval_pos,\n\u001B[32m    635\u001B[39m     half_layers=half_layers,\n\u001B[32m    636\u001B[39m     cache_trainset_representation=\u001B[38;5;28mself\u001B[39m.cache_trainset_representation,\n\u001B[32m    637\u001B[39m )  \u001B[38;5;66;03m# b s f+1 e -> b s f+1 e\u001B[39;00m\n\u001B[32m    639\u001B[39m \u001B[38;5;66;03m# If we are using a decoder\u001B[39;00m\n\u001B[32m    640\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.transformer_decoder:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1734\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1735\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1736\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_impl(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1742\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1743\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1744\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1745\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1746\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1747\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(*args, **kwargs)\n\u001B[32m   1749\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1750\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/tabpfn/model/transformer.py:89\u001B[39m, in \u001B[36mLayerStack.forward\u001B[39m\u001B[34m(self, x, half_layers, **kwargs)\u001B[39m\n\u001B[32m     87\u001B[39m         x = checkpoint(partial(layer, **kwargs), x, use_reentrant=\u001B[38;5;28;01mFalse\u001B[39;00m)  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[32m     88\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m89\u001B[39m         x = layer(x, **kwargs)\n\u001B[32m     91\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1734\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1735\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1736\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_impl(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1742\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1743\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1744\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1745\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1746\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1747\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(*args, **kwargs)\n\u001B[32m   1749\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1750\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/tabpfn/model/layer.py:449\u001B[39m, in \u001B[36mPerFeatureEncoderLayer.forward\u001B[39m\u001B[34m(self, state, single_eval_pos, cache_trainset_representation, att_src)\u001B[39m\n\u001B[32m    439\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[32m    440\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mPre-norm implementation is wrong, as the residual should never\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    441\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m be layer normed here.\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    442\u001B[39m     )\n\u001B[32m    443\u001B[39m     state = layer_norm(\n\u001B[32m    444\u001B[39m         state,\n\u001B[32m    445\u001B[39m         allow_inplace=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m    446\u001B[39m         save_peak_mem_factor=save_peak_mem_factor,\n\u001B[32m    447\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m449\u001B[39m state = sublayer(state)\n\u001B[32m    450\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m.pre_norm:\n\u001B[32m    451\u001B[39m     state = layer_norm(\n\u001B[32m    452\u001B[39m         state,\n\u001B[32m    453\u001B[39m         allow_inplace=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m    454\u001B[39m         save_peak_mem_factor=save_peak_mem_factor,\n\u001B[32m    455\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/tabpfn/model/layer.py:363\u001B[39m, in \u001B[36mPerFeatureEncoderLayer.forward.<locals>.attn_between_items\u001B[39m\u001B[34m(x)\u001B[39m\n\u001B[32m    360\u001B[39m     new_x_test = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    362\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m single_eval_pos:\n\u001B[32m--> \u001B[39m\u001B[32m363\u001B[39m     new_x_train = \u001B[38;5;28mself\u001B[39m.self_attn_between_items(\n\u001B[32m    364\u001B[39m         x[:, :single_eval_pos].transpose(\u001B[32m1\u001B[39m, \u001B[32m2\u001B[39m),\n\u001B[32m    365\u001B[39m         x[:, :single_eval_pos].transpose(\u001B[32m1\u001B[39m, \u001B[32m2\u001B[39m),\n\u001B[32m    366\u001B[39m         save_peak_mem_factor=save_peak_mem_factor,\n\u001B[32m    367\u001B[39m         cache_kv=cache_trainset_representation,\n\u001B[32m    368\u001B[39m         only_cache_first_head_kv=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m    369\u001B[39m         add_input=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m    370\u001B[39m         allow_inplace=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m    371\u001B[39m         use_cached_kv=\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m    372\u001B[39m     ).transpose(\u001B[32m1\u001B[39m, \u001B[32m2\u001B[39m)\n\u001B[32m    373\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    374\u001B[39m     new_x_train = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1734\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1735\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1736\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_impl(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1742\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1743\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1744\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1745\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1746\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1747\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(*args, **kwargs)\n\u001B[32m   1749\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1750\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/tabpfn/model/multi_head_attention.py:355\u001B[39m, in \u001B[36mMultiHeadAttention.forward\u001B[39m\u001B[34m(self, x, x_kv, cache_kv, add_input, allow_inplace, save_peak_mem_factor, reuse_first_head_kv, only_cache_first_head_kv, use_cached_kv, use_second_set_of_queries)\u001B[39m\n\u001B[32m    338\u001B[39m         \u001B[38;5;28mself\u001B[39m._k_cache = torch.empty(\n\u001B[32m    339\u001B[39m             batch_size,\n\u001B[32m    340\u001B[39m             seqlen_kv,\n\u001B[32m   (...)\u001B[39m\u001B[32m    344\u001B[39m             dtype=x.dtype,\n\u001B[32m    345\u001B[39m         )\n\u001B[32m    346\u001B[39m         \u001B[38;5;28mself\u001B[39m._v_cache = torch.empty(\n\u001B[32m    347\u001B[39m             batch_size,\n\u001B[32m    348\u001B[39m             seqlen_kv,\n\u001B[32m   (...)\u001B[39m\u001B[32m    352\u001B[39m             dtype=x.dtype,\n\u001B[32m    353\u001B[39m         )\n\u001B[32m--> \u001B[39m\u001B[32m355\u001B[39m output: torch.Tensor = \u001B[38;5;28mself\u001B[39m._compute(\n\u001B[32m    356\u001B[39m     x,\n\u001B[32m    357\u001B[39m     x_kv,\n\u001B[32m    358\u001B[39m     \u001B[38;5;28mself\u001B[39m._k_cache,\n\u001B[32m    359\u001B[39m     \u001B[38;5;28mself\u001B[39m._v_cache,\n\u001B[32m    360\u001B[39m     \u001B[38;5;28mself\u001B[39m._kv_cache,\n\u001B[32m    361\u001B[39m     cache_kv=cache_kv,\n\u001B[32m    362\u001B[39m     use_cached_kv=use_cached_kv,\n\u001B[32m    363\u001B[39m     add_input=add_input,\n\u001B[32m    364\u001B[39m     allow_inplace=allow_inplace,\n\u001B[32m    365\u001B[39m     save_peak_mem_factor=save_peak_mem_factor,\n\u001B[32m    366\u001B[39m     reuse_first_head_kv=reuse_first_head_kv,\n\u001B[32m    367\u001B[39m     use_second_set_of_queries=use_second_set_of_queries,\n\u001B[32m    368\u001B[39m )\n\u001B[32m    369\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m output.reshape(x_shape_after_transpose[:-\u001B[32m1\u001B[39m] + output.shape[-\u001B[32m1\u001B[39m:])\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/tabpfn/model/memory.py:94\u001B[39m, in \u001B[36msupport_save_peak_mem_factor.<locals>.method_\u001B[39m\u001B[34m(self, x, add_input, allow_inplace, save_peak_mem_factor, *args, **kwargs)\u001B[39m\n\u001B[32m     92\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m x_, *args_ \u001B[38;5;129;01min\u001B[39;00m split_args:\n\u001B[32m     93\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m add_input:\n\u001B[32m---> \u001B[39m\u001B[32m94\u001B[39m         x_[:] += method(\u001B[38;5;28mself\u001B[39m, x_, *args_, **kwargs)\n\u001B[32m     95\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     96\u001B[39m         x_[:] = method(\u001B[38;5;28mself\u001B[39m, x_, *args_, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/tabpfn/model/multi_head_attention.py:504\u001B[39m, in \u001B[36mMultiHeadAttention._compute\u001B[39m\u001B[34m(self, x, x_kv, k_cache, v_cache, kv_cache, cache_kv, use_cached_kv, reuse_first_head_kv, use_second_set_of_queries)\u001B[39m\n\u001B[32m    490\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Attention computation.\u001B[39;00m\n\u001B[32m    491\u001B[39m \u001B[33;03mCalled by 'forward', potentially on shards, once shapes have been normalized.\u001B[39;00m\n\u001B[32m    492\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    493\u001B[39m q, k, v, kv, qkv = \u001B[38;5;28mself\u001B[39m.compute_qkv(\n\u001B[32m    494\u001B[39m     x,\n\u001B[32m    495\u001B[39m     x_kv,\n\u001B[32m   (...)\u001B[39m\u001B[32m    502\u001B[39m     use_second_set_of_queries=use_second_set_of_queries,\n\u001B[32m    503\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m504\u001B[39m attention_head_outputs = MultiHeadAttention.compute_attention_heads(\n\u001B[32m    505\u001B[39m     q,\n\u001B[32m    506\u001B[39m     k,\n\u001B[32m    507\u001B[39m     v,\n\u001B[32m    508\u001B[39m     kv,\n\u001B[32m    509\u001B[39m     qkv,\n\u001B[32m    510\u001B[39m     \u001B[38;5;28mself\u001B[39m.dropout_p,\n\u001B[32m    511\u001B[39m     \u001B[38;5;28mself\u001B[39m.softmax_scale,\n\u001B[32m    512\u001B[39m )\n\u001B[32m    513\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m torch.einsum(\n\u001B[32m    514\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33m... h d, h d s -> ... s\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    515\u001B[39m     attention_head_outputs,\n\u001B[32m    516\u001B[39m     \u001B[38;5;28mself\u001B[39m._w_out,\n\u001B[32m    517\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/tabpfn/model/multi_head_attention.py:729\u001B[39m, in \u001B[36mMultiHeadAttention.compute_attention_heads\u001B[39m\u001B[34m(q, k, v, kv, qkv, dropout_p, softmax_scale)\u001B[39m\n\u001B[32m    727\u001B[39m     ps = torch.softmax(logits, dim=\u001B[32m2\u001B[39m)\n\u001B[32m    728\u001B[39m     ps = torch.dropout(ps, dropout_p, train=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m--> \u001B[39m\u001B[32m729\u001B[39m     attention_head_outputs = torch.einsum(\u001B[33m\"\u001B[39m\u001B[33mb q k h, b k h d -> b q h d\u001B[39m\u001B[33m\"\u001B[39m, ps, v)\n\u001B[32m    731\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m attention_head_outputs.reshape(\n\u001B[32m    732\u001B[39m     batch_size,\n\u001B[32m    733\u001B[39m     seqlen_q,\n\u001B[32m    734\u001B[39m     nhead,\n\u001B[32m    735\u001B[39m     d_v,\n\u001B[32m    736\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/tabpfn_credit_codebase/lib/python3.12/site-packages/torch/functional.py:402\u001B[39m, in \u001B[36meinsum\u001B[39m\u001B[34m(*args)\u001B[39m\n\u001B[32m    397\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m einsum(equation, *_operands)\n\u001B[32m    399\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(operands) <= \u001B[32m2\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m opt_einsum.enabled:\n\u001B[32m    400\u001B[39m     \u001B[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001B[39;00m\n\u001B[32m    401\u001B[39m     \u001B[38;5;66;03m# or the user has disabled using opt_einsum\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m402\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m _VF.einsum(equation, operands)  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[32m    404\u001B[39m path = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    405\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m opt_einsum.is_available():\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T09:44:16.525138Z",
     "start_time": "2025-05-27T09:44:16.522444Z"
    }
   },
   "cell_type": "code",
   "source": "scoring",
   "id": "7e0ec34f669d5976",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'roc_auc'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T09:44:01.532333Z",
     "start_time": "2025-05-27T09:44:01.516801Z"
    }
   },
   "cell_type": "code",
   "source": "scores_raw_class",
   "id": "9f9d5dfa6a28f9a9",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scores_raw_class' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m scores_raw_class\n",
      "\u001B[31mNameError\u001B[39m: name 'scores_raw_class' is not defined"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c33d952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "df = pd.DataFrame(list(scores_class.items()), columns=['Model', 'ROC AUC'])\n",
    "colors = ['tab:blue' if 'RF' in name else ('tab:red' if 'sample' in name else 'tab:gray') for (name, _) in models_class]\n",
    "ax = df.plot(x='Model', y='ROC AUC', kind='bar', figsize=(10, 6), color=colors)\n",
    "ax.set_ylim(df['ROC AUC'].min() * 0.995, min(1.0, df['ROC AUC'].max() * 1.005))\n",
    "ax.set_title('Model Comparison - 5-fold Cross-validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d0539e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tabpfn)",
   "language": "python",
   "name": "tabpfn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
