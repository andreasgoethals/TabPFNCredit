#tune_hyperparameters: false  # true: tune hyperparameters, false: use stored hyperparameters

missing_values: 1  # 0: don't handle missing values, 1: drop rows with missing values, 2: impute with mode(cat) and mean(num), 3: impute with median(num) and mode(cat)
encode_cat: 1  # 0: no encoding, 1: one-hot, 2: WoE encoding
standardize: 2  # 0: no standardization, 1: standardnormal distribution, 2: min-max scaling

methods:
  pd:
    ab: false    # AdaBoost (AB)
    ann: false   # Artificial Neural Networks (ANN)
    bnb: false   # Bernoulli Naive Bayes (BNB)
    cb: false    # CatBoost (CB)
    dt: false    # Decision Tree (DT)
    gnb: false   # Gaussian Naive Bayes (GNB)
    knn: false   # K-Nearest Neighbors (KNN)
    lda: false   # Linear Discriminant Analysis (LDA)
    lgbm: false  # LightGBM (LGBM)
    lr: true    # Logistic Regression (LR)
    rf: true # Random Forest (RF)
    svm: false   # Support Vector Machine (SVM)
    tabnet: false   # TabNet
    tabpfn: false   # TabPFN foundation model
    xgb: false   # Extreme Gradient Boosting (XGBoost)
  lgd:
    ab: true      # AdaBoost Regression (AB)
    ann: true     # Artificial Neural Networks (ANN)
    cb: true      # CatBoost Regression (CB)
    dt: true      # Decision Tree Regression (DT)
    en: true      # Elastic Net Regression (EN)
    knn: true     # K-Nearest Neighbors Regression (KNN)
    lgbm: true    # LightGBM Regression (LGBM)
    lr: true      # Linear Regression (LR)
    rf: true      # Random Forest Regression (RF)
    svr: true     # Support Vector Regression (SVR)
    tabnet: true  # TabNet Regression (TabNet)
    tabpfn: true  # TabPFN Regression (TabPFN)
    xgb: true     # Extreme Gradient Boosting Regression (XGB)