
tune_hyperparameters: false,  # Whether to tune hyperparameters or not



methods_lgd:

methods_pd:
  'ab': True,    # AdaBoost (AB)
  'ann': True,   # Artificial Neural Networks (ANN)
  'bnb': True,   # Bernoulli Naive Bayes (BNB)
  'cb': False,   # CatBoost (CB)
  'dt': True,    # Decision Tree (DT)
  'gnb': True,   # Gaussian Naive Bayes (GNB)
  'gb': True,    # Gradient Boosting (GB)
  'knn': True,   # K-Nearest Neighbors (KNN)
  'lgbm': True,  # LightGBM (LGBM)
  'lda': True,   # Linear Discriminant Analysis (LDA)
  'lr': True,    # Logistic Regression (LR)
  'mnb': False,  # Multinomial Naive Bayes (MNB)
  'pac': False,  # Passive Aggressive Classifier (PAC)
  'per': False,  # Perceptron (Per)
  'qda': True,   # Quadratic Discriminant Analysis (QDA)
  'rf': True,    # Random Forest (RF)
  'rc': False,   # Ridge Classifier (RC)
  'sgd': False,  # Stochastic Gradient Descent (SGD)
  'svm': True,   # Support Vector Machine (SVM)
  'xgb': True    # Extreme Gradient Boosting (XGBoost)

binary_threshold: 0.5,  # Threshold for binary classification


hyperparameters: # For each method, the hyperparameters to tune
  - method: "xgb"
    n_estimators: [50, 100, 150]
    max_depth: [3, 5, 7]
    learning_rate: [0.01, 0.1, 0.2]
    gamma: [0, 0.1, 0.2]
    min_child_weight: [1, 5, 10]
    subsample: [0.8, 1.0]
    colsample_bytree: [0.8, 1.0]
    reg_alpha: [0, 0.01, 0.1]

  - method: "rf"
    n_estimators: [100, 200, 300]
    max_depth: [3, 5, None]
    min_samples_split: [2, 5, 10]
    min_samples_leaf: [1, 2, 4]
    max_features: ["auto", "sqrt", "log2"]
    bootstrap: [true, false]

  - method: "svm"
    C: [0.1, 1, 10]
    kernel: ["linear", "rbf", "poly"]
    degree: [2, 3, 4]
    gamma: ["scale", "auto"]
    coef0: [0, 0.1, 0.2]


